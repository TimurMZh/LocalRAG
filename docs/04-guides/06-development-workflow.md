# Рабочий процесс разработки

Репозиторий спроектирован так, чтобы обеспечить структурированный путь от начальной настройки до полностью функционального AI приложения. Это руководство проведет вас через процесс преобразования шаблона в ваше собственное приложение, с подробными объяснениями каждого шага и лучшими практиками.

## Начало работы с шаблоном

Начните с клонирования ветки boilerplate, которая предоставляет чистую основу для вашего проекта:

```bash
git clone -b boilerplate https://github.com/noteldar/llm-pipeline
cd llm-pipeline
```
Ветка boilerplate содержит базовую инфраструктуру без какой-либо специфической бизнес-логики, позволяя вам создавать ваше приложение с чистого листа, при этом используя преимущества надежной архитектурной основы.

## Конфигурация окружения

Первым шагом в настройке вашего приложения является настройка конфигурации окружения. Это включает создание и настройку двух важных .env файлов:

```bash
cp app/.env.example app/.env
cp docker/.env.example docker/.env
```
В вашем файле `app/.env` вам необходимо добавить учетные данные провайдера AI. Как минимум, вы должны настроить:

- OPENAI_API_KEY для интеграции с OpenAI
- ANTHROPIC_API_KEY если вы планируете использовать Claude
- Любые другие ключи, специфичные для провайдеров, которые требуются вашему приложению

Файл `docker/.env` содержит конфигурации инфраструктуры. Хотя значения по умолчанию хорошо работают для разработки, вам следует обновить:

- Учетные данные базы данных для безопасности
- Настройки домена при развертывании в production
- Любые специфические для сервиса конфигурации

## Определение событий вашего приложения

События являются основными строительными блоками функциональности вашего приложения. Начните с определения ваших событий в директории requests/events. Каждое событие должно быть JSON файлом, который представляет определенное взаимодействие или процесс в вашей системе. Например:

```json
{
    "type": "document_analysis",
    "data": {
        "content": "Document text here...",
        "analysis_type": "sentiment",
        "metadata": {
            "source": "email",
            "priority": "high"
        }
    }
}
```
Эти определения событий служат как документацией, так и тестовыми фикстурами для вашего приложения.

## Определение схем

После того, как вы определили ваши события, создайте соответствующие схемы в `app/api/event_schema.py`. Эти Pydantic модели будут проверять входящие запросы и обеспечивать типобезопасность во всем вашем приложении:

```python
class DocumentAnalysisEvent(BaseModel):
    content: str
    analysis_type: str
    metadata: Dict[str, Any] = Field(default_factory=dict)
```
Определения схем критически важны, поскольку они формируют контракт между вашим API и его клиентами, обеспечивая согласованность данных и предоставляя автоматическую документацию API.

## Создание AI конвейеров

После определения событий и схем вы можете начать создавать конвейеры, которые будут обрабатывать эти события. В `app/pipelines/` создайте новую директорию для каждой основной функциональной области. Каждый конвейер должен состоять из сфокусированных, переиспользуемых узлов, которые обрабатывают определенные аспекты обработки.

Например, конвейер анализа документов может включать:

- Узел извлечения текста
- Узел классификации
- Узел анализа тональности
- Узел форматирования ответа

## Интеграция с Vector Store (Опционально)

Если ваше приложение требует возможностей семантического поиска или сопоставления по схожести, вам нужно будет заполнить ваше векторное хранилище. Утилита `app/utils/insert_vectors.py` помогает добавить эмбеддинги в базу данных PostgreSQL:

```python
python app/utils/insert_vectors.py
```
Этот шаг особенно важен для приложений, реализующих паттерны RAG (Retrieval-Augmented Generation) или функциональность семантического поиска.

## Эксперименты и улучшения

Директория playground - это ваша лаборатория для тестирования и улучшения AI взаимодействий. Используйте эти скрипты для:

- Тестирования различных стратегий промптов
- Экспериментов с различными параметрами LLM
- Проверки поведения конвейеров
- Измерения производительности и затрат

Playground обеспечивает быстрый цикл обратной связи для разработки и тестирования ваших AI компонентов перед их интеграцией в основной поток приложения.

## Тестирование и валидация

По мере разработки вашего приложения поддерживайте полный набор тестовых событий в `requests/events/`. Используйте утилиты тестирования для проверки ваших конвейеров:

```python
from utils.event_factory import EventFactory
from pipelines.your_pipeline import YourPipeline

def test_pipeline():
    event = EventFactory.create_event("your_test_event")
    pipeline = YourPipeline()
    result = pipeline.run(event)
    assert result.nodes["AnalysisNode"]["status"] == "success"
```
## Итеративная разработка

Разработка с Репозиторием - это итеративный процесс. Начните с минимально жизнеспособного конвейера и постепенно улучшайте его на основе:

- Метрик производительности
- Обратной связи от пользователей
- Паттернов ошибок
- Соображений стоимости

Модульная архитектура позволяет улучшать отдельные компоненты, не затрагивая остальную часть системы.

## Следующие шаги

После завершения начальной разработки:

- Настройте мониторинг и логирование (мы используем LangFuse)
- Реализуйте стратегии обработки ошибок
- Настройте развертывание в продакшн
- Документируйте ваши пользовательские компоненты

Помните, что Репозиторий спроектирован для роста вместе с вашими потребностями. Начните с простого и расширяйте реализацию по мере развития ваших требований.
